{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from matplotlib.legend import _get_legend_handles_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # disable debugging logs from Tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rc('xtick',labelsize=19)\n",
    "plt.rc('ytick',labelsize=19)\n",
    "plt.rc('axes', labelsize=20, titlesize=16)\n",
    "# To plot consistent and pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "mpl.rcParams['font.family'] = 'times new roman'\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "mpl.rcParams['savefig.dpi'] = 120\n",
    "def function(x):\n",
    "    \"\"\"One-dimensional x*sin(x) function.\"\"\"\n",
    "    return x * np.cos(x)\n",
    "\n",
    "def data_het(\n",
    "    funct, min_x, max_x, n_samples, noise\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate 1D noisy data uniformly from the given function\n",
    "    and standard deviation for the noise.\n",
    "    Parameters:\n",
    "        funct (function): The function used to generate the data.\n",
    "        min_x (float): Minimum value for the x-axis range.\n",
    "        max_x (float): Maximum value for the x-axis range.\n",
    "        n_samples (int): Number of data samples to generate.\n",
    "        noise (float): Standard deviation of the Gaussian noise to add to the data.\n",
    "    \n",
    "    Returns:\n",
    "        X_train (numpy array): Training input data.\n",
    "        y_train (numpy array): Noisy training output data.\n",
    "        X_test (numpy array): Test input data.\n",
    "        y_test (numpy array): Noisy test output data.\n",
    "        y_mesh (numpy array): True output data without noise for test points.\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(59)\n",
    "    X_train = np.linspace(min_x, max_x, n_samples)\n",
    "    np.random.shuffle(X_train)\n",
    "    X_test = np.linspace(min_x, max_x, n_samples * 10)\n",
    "    y_train = (\n",
    "        funct(X_train) +\n",
    "        (np.random.normal(0, noise, len(X_train)) * X_train)\n",
    "    )\n",
    "    y_test = (\n",
    "        funct(X_test) +\n",
    "        (np.random.normal(0, noise, len(X_test)) * X_test)\n",
    "    )\n",
    "    y_mesh = funct(X_test)\n",
    "    return (\n",
    "        X_train.reshape(-1, 1), y_train, X_test.reshape(-1, 1), y_test, y_mesh\n",
    "    )\n",
    "\n",
    "\n",
    "def jackknife_plus(X,Y,Xtest,Ytest,alpha):\n",
    "    \"\"\"\n",
    "    Calculate prediction intervals using the jackknife-plus method.\n",
    "    \n",
    "    Parameters:\n",
    "        X (numpy array): Training input data.\n",
    "        Y (numpy array): Noisy training output data.\n",
    "        Xtest (numpy array): Test input data.\n",
    "        Ytest (numpy array): Noisy test output data.\n",
    "        alpha (float): Confidence level (e.g., 0.95 for 95% confidence).\n",
    "    \n",
    "    Returns:\n",
    "        res (list): List containing [alpha, coverage, width, PIs].\n",
    "            - alpha (float): The specified confidence level.\n",
    "            - coverage (float): The actual coverage probability of the prediction intervals.\n",
    "            - width (float): The average width of the prediction intervals.\n",
    "            - PIs (numpy array): Array of shape (ntest, 2) containing the prediction intervals for each test point.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]              \n",
    "    ntest = Xtest.shape[0]         \n",
    "    R = np.zeros(n)              \n",
    "    y_pred=np.zeros((n,ntest))\n",
    "    res=[]\n",
    "    for i in np.arange(n):\n",
    "        X_ = np.delete(X,i,0)\n",
    "        Y_ = np.delete(Y,i)\n",
    "        polyn_model.fit(X_, Y_)\n",
    "        R[i] = np.abs(Y[i] - polyn_model.predict(X[i].reshape(1, -1)))\n",
    "        y_pred[i]=polyn_model.predict(Xtest)\n",
    "    PIs = np.zeros((ntest,2))    \n",
    "    for itest in np.arange(ntest):\n",
    "        q_lo = np.sort(y_pred[:,itest]-R)[::-1][(np.ceil((1-alpha)*(n+1))).astype(int)]\n",
    "        q_hi = np.sort(y_pred[:,itest]+R)[(np.ceil((1-alpha)*(n+1))).astype(int)]\n",
    "        PIs[itest] = np.array([q_lo,q_hi])\n",
    "    coverage=round(regression_coverage_score(Ytest, PIs[:,0], PIs[:,1]),3)\n",
    "    width=( PIs[:,1] - PIs[:,0]).mean().round(3)\n",
    "    ypred = PIs.mean(axis=1)\n",
    "    res.append([alpha,coverage,width,PIs])\n",
    "    return res\n",
    "def weighted_jackknife_plus(X,Y,Xtest,Ytest,alpha):\n",
    "    \"\"\"\n",
    "    Calculate weighted prediction intervals using the weighted jackknife-plus method.\n",
    "    \n",
    "    Parameters:\n",
    "        X (numpy array): Training input data.\n",
    "        Y (numpy array): Noisy training output data.\n",
    "        Xtest (numpy array): Test input data.\n",
    "        Ytest (numpy array): Noisy test output data.\n",
    "        alpha (float): Confidence level (e.g., 0.95 for 95% confidence).\n",
    "    \n",
    "    Returns:\n",
    "        res (list): List containing [alpha, coverage, width, PIs].\n",
    "            - alpha (float): The specified confidence level.\n",
    "            - coverage (float): The actual coverage probability of the prediction intervals.\n",
    "            - width (float): The average width of the prediction intervals.\n",
    "            - PIs (numpy array): Array of shape (ntest, 2) containing the prediction intervals for each test point.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]              \n",
    "    ntest = Xtest.shape[0]          \n",
    "    R = np.zeros(n)              \n",
    "    y_pred=np.zeros((n,ntest))\n",
    "    d=np.zeros((n,ntest))\n",
    "    w=np.zeros((n,ntest))\n",
    "    res=[]\n",
    "    for i in np.arange(n):\n",
    "        X_ = np.delete(X,i,0)\n",
    "        Y_ = np.delete(Y,i)\n",
    "        polyn_model.fit(X_, Y_)\n",
    "        R[i] = np.abs(Y[i] - polyn_model.predict(X[i].reshape(1, -1)))\n",
    "        y_pred[i]=polyn_model.predict(Xtest)\n",
    "        d[i]=1/(cdist(X[i].reshape(1,-1),Xtest,'euclidean')) \n",
    "\n",
    "    PIs = np.zeros((ntest,2))    \n",
    "   \n",
    "    for itest in np.arange(ntest):\n",
    "        w[:,itest] = d[:,itest]/d[:,itest].sum()\n",
    "        q_lo = np.sort(y_pred[:,itest]-(w[:,itest]*R*n))[::-1][(np.ceil((1-alpha)*(n+1))).astype(int)]\n",
    "        q_hi = np.sort(y_pred[:,itest]+(w[:,itest]*R*n))[(np.ceil((1-alpha)*(n+1))).astype(int)]\n",
    "        PIs[itest] = np.array([q_lo,q_hi])\n",
    "\n",
    "    coverage=round(regression_coverage_score(Ytest, PIs[:,0], PIs[:,1]),3)\n",
    "    width=( PIs[:,1] - PIs[:,0]).mean().round(3)\n",
    "    ypred = PIs.mean(axis=1)\n",
    "    res.append([alpha,coverage,width,PIs])\n",
    "    return res\n",
    "\n",
    "\n",
    "def plot(\n",
    "    \"\"\"\n",
    "    Plot the training data, prediction intervals, and optionally the test data.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (numpy array): Training input data.\n",
    "        y_train (numpy array): Noisy training output data.\n",
    "        X_test (numpy array): Test input data.\n",
    "        y_test (numpy array): Noisy test output data.\n",
    "        y_pred (numpy array): Mean predictions for the test points.\n",
    "        y_pred_low (numpy array): Lower bounds of the prediction intervals.\n",
    "        y_pred_up (numpy array): Upper bounds of the prediction intervals.\n",
    "        ax (matplotlib axis, optional): The axis on which to plot the data. If None, a new figure and axis will be created.\n",
    "        title (str, optional): Title for the plot.\n",
    "    \"\"\"\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_low,\n",
    "    y_pred_up,\n",
    "    ax=None,\n",
    "    title=None,\n",
    "):\n",
    "    ax.fill_between(X_test, y_pred_low, y_pred_up,color='lightgray', alpha=0.5, label=\"Prediction intervals\")\n",
    "    ax.scatter(X_train, y_train,color=\"red\", s=10, alpha=0.3, label=\"Data point\") \n",
    "#     ax.scatter(X_test, y_test,color=\"orange\", s=1, alpha=0.3, label=\"Test data\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title,fontweight ='bold',fontsize=14)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
